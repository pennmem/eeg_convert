{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tables  # enables reading BLOSC compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full session loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_eeg(root: Path) -> np.ndarray:\n",
    "    \"\"\"Load a full session of split EEG data.\n",
    "    \n",
    "    :param root: rhino root path\n",
    "    :returns: full session EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    path = root.joinpath(\"protocols\", \"r1\",\n",
    "                         \"subjects\", \"R1111M\",\n",
    "                         \"experiments\", \"FR1\",\n",
    "                         \"sessions\", \"0\",\n",
    "                         \"ephys\", \"current_processed\", \"noreref\")\n",
    "    files = sorted(path.glob(\"*\"))\n",
    "    return np.array([np.fromfile(str(infile), dtype=\"int16\") for infile in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_eeg(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load a full session of HDF5 EEG data.\n",
    "    \n",
    "    :param path: path to HDF5 file\n",
    "    :returns: full session EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(str(path), \"r\") as hfile:\n",
    "        eeg = hfile[\"eeg\"]\n",
    "        arr = np.empty(eeg.shape, dtype=eeg.dtype)\n",
    "        eeg.read_direct(arr)\n",
    "        return arr\n",
    "        # return hfile[\"eeg\"][0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 53.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.11 s ± 8.81 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data = load_split_eeg(Path(\"/Users/depalati/mnt/rhino\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "# GZIP compression level 9, shuffle not set\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_gzip_9.h5\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "# GZIP compression level 9, shuffle=True\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_gzip_9_shuffle.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 17.09 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1.2 s ± 2.03 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# BLOSC compression (requires PyTables)\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_blosc.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 13.83 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "815 ms ± 1.28 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# no compression\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_no_compression.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 ms ± 13.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# no chunking\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/no_chunks.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_eeg_epochs(root: Path) -> np.ndarray:\n",
    "    \"\"\"Load epochs from split EEG data.\n",
    "    \n",
    "    :param root:\n",
    "    :returns: n_events x n_channels x time array\n",
    "    \n",
    "    \"\"\"\n",
    "    path = root.joinpath(\"protocols\", \"r1\",\n",
    "                         \"subjects\", \"R1111M\",\n",
    "                         \"experiments\", \"FR1\",\n",
    "                         \"sessions\", \"0\",\n",
    "                         \"ephys\", \"current_processed\", \"noreref\")\n",
    "    files = sorted(path.glob(\"*\"))\n",
    "    mmaps = [np.memmap(f, dtype=\"int16\") for f in files]\n",
    "    epochs = np.array([(start, start + 500) for start in range(0, 1623000, 1000)])\n",
    "    n_epochs = epochs.shape[0]\n",
    "\n",
    "    # shape: (channels, time, epochs)\n",
    "    data = [\n",
    "        [mmap[epochs[i, 0]:epochs[i, 1]] for i in range(n_epochs)]\n",
    "        for mmap in mmaps\n",
    "    ]\n",
    "    return np.transpose(data, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 261 ms, total: 1.46 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_split_eeg_epochs(Path(\"/Users/depalati/mnt/rhino\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_eeg_epochs(path) -> np.ndarray:\n",
    "    \"\"\"Load epochs from HDF5 EEG data.\n",
    "    \n",
    "    :param path: path to HDF5 file\n",
    "    :returns: EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    def epochs_gen():\n",
    "        for start in range(0, 1623000, 5000):\n",
    "            yield range(start, start + 500)\n",
    "    \n",
    "    epochs = epochs_gen()\n",
    "    \n",
    "    with h5py.File(path, \"r\") as hfile:\n",
    "        dset = hfile[\"eeg\"]\n",
    "        arr = np.empty((325, dset.shape[1], 500), dtype=dset.dtype)\n",
    "        for i, epoch in enumerate(epochs):\n",
    "            dset.read_direct(arr, np.s_[0, :, epoch], np.s_[i])\n",
    "        return arr\n",
    "        \n",
    "        return [\n",
    "            hfile[\"eeg\"][0, :, epoch]\n",
    "            for epoch in epochs\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.3 s, sys: 434 ms, total: 3.73 s\n",
      "Wall time: 3.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_no_compression.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325, 100, 500)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.48 s, sys: 1.52 s, total: 6 s\n",
      "Wall time: 26.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_blosc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 s, sys: 1.59 s, total: 43.7 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_gzip_9.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfile = h5py.File(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_no_compression.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = list([range(0, 100), range(200, 300)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3596, 3595, 3596, 3599, 3601, 3596, 3597, 3601, 3605, 3614, 3624,\n",
       "        3629, 3634, 3636, 3646, 3656, 3661, 3661, 3667, 3674, 3681, 3693,\n",
       "        3695, 3701, 3708, 3710, 3723, 3732, 3736, 3734, 3730, 3728, 3727,\n",
       "        3727, 3727, 3729, 3726, 3724, 3722, 3717, 3711, 3710, 3697, 3689,\n",
       "        3683, 3677, 3670, 3670, 3666, 3662, 3659, 3658, 3653, 3649, 3635,\n",
       "        3626, 3625, 3618, 3603, 3594, 3589, 3582, 3577, 3576, 3566, 3559,\n",
       "        3552, 3548, 3550, 3550, 3554, 3559, 3563, 3569, 3566, 3573, 3580,\n",
       "        3582, 3581, 3583, 3588, 3588, 3590, 3596, 3595, 3594, 3595, 3598,\n",
       "        3615, 3622, 3631, 3629, 3629, 3633, 3637, 3634, 3623, 3611, 3607,\n",
       "        3605], dtype=int16),\n",
       " array([3507, 3511, 3520, 3521, 3518, 3514, 3513, 3508, 3508, 3505, 3511,\n",
       "        3504, 3498, 3497, 3493, 3487, 3480, 3476, 3478, 3479, 3479, 3489,\n",
       "        3489, 3487, 3488, 3497, 3503, 3511, 3513, 3511, 3511, 3504, 3502,\n",
       "        3498, 3498, 3498, 3504, 3503, 3506, 3498, 3498, 3497, 3500, 3502,\n",
       "        3508, 3516, 3529, 3529, 3535, 3544, 3548, 3550, 3561, 3564, 3569,\n",
       "        3579, 3593, 3599, 3613, 3615, 3623, 3626, 3628, 3629, 3632, 3625,\n",
       "        3626, 3623, 3631, 3633, 3640, 3643, 3638, 3634, 3635, 3632, 3632,\n",
       "        3633, 3631, 3631, 3621, 3610, 3596, 3577, 3563, 3556, 3547, 3534,\n",
       "        3529, 3524, 3513, 3506, 3495, 3491, 3484, 3479, 3470, 3454, 3442,\n",
       "        3434], dtype=int16)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hfile[\"eeg\"][0, 0, chunk] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
