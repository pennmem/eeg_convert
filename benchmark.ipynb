{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tables  # enables reading BLOSC compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full session loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_eeg(root: Path) -> np.ndarray:\n",
    "    \"\"\"Load a full session of split EEG data.\n",
    "    \n",
    "    :param root: rhino root path\n",
    "    :returns: full session EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    path = root.joinpath(\"protocols\", \"r1\",\n",
    "                         \"subjects\", \"R1111M\",\n",
    "                         \"experiments\", \"FR1\",\n",
    "                         \"sessions\", \"0\",\n",
    "                         \"ephys\", \"current_processed\", \"noreref\")\n",
    "    files = sorted(path.glob(\"*\"))\n",
    "    return np.array([np.fromfile(str(infile), dtype=\"int16\") for infile in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_eeg(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load a full session of HDF5 EEG data.\n",
    "    \n",
    "    :param path: path to HDF5 file\n",
    "    :returns: full session EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(str(path), \"r\") as hfile:\n",
    "        eeg = hfile[\"eeg\"]\n",
    "        arr = np.empty(eeg.shape, dtype=eeg.dtype)\n",
    "        eeg.read_direct(arr)\n",
    "        return arr\n",
    "        # return hfile[\"eeg\"][0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 53.48 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "4.11 s ± 8.81 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data = load_split_eeg(Path(\"/Users/depalati/mnt/rhino\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "# GZIP compression level 9, shuffle not set\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_gzip_9.h5\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%timeit\n",
    "# GZIP compression level 9, shuffle=True\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_gzip_9_shuffle.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 17.09 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1.2 s ± 2.03 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# BLOSC compression (requires PyTables)\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_blosc.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 13.83 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "815 ms ± 1.28 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# no compression\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_no_compression.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186 ms ± 13.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# no chunking\n",
    "data = load_hdf5_eeg(Path(\"/Users/depalati/rhino_home/scratch/no_chunks.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochs_gen():\n",
    "    for start in range(0, 1623000, 5000):\n",
    "        yield start, start + 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = 500\n",
    "epochs = [(start, start + dur) for start in range(0, 1623000, 5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_eeg_epochs(root, epochs) -> np.ndarray:\n",
    "    \"\"\"Load epochs from split EEG data.\n",
    "    \n",
    "    :param root:\n",
    "    :returns: n_events x n_channels x time array\n",
    "    \n",
    "    \"\"\"\n",
    "    path = root.joinpath(\"protocols\", \"r1\",\n",
    "                         \"subjects\", \"R1111M\",\n",
    "                         \"experiments\", \"FR1\",\n",
    "                         \"sessions\", \"0\",\n",
    "                         \"ephys\", \"current_processed\", \"noreref\")\n",
    "    files = sorted(path.glob(\"*\"))\n",
    "    mmaps = [np.memmap(f, dtype=\"int16\") for f in files]\n",
    "    duration = epochs[0][1] - epochs[0][0]\n",
    "\n",
    "    data = np.empty((len(epochs), len(files), duration), dtype=\"int16\")\n",
    "    \n",
    "    for i, epoch in enumerate(epochs):\n",
    "        data[i, :] = [mmap[epoch[0]:epoch[1]] for mmap in mmaps]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376 ms ± 4.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "split_data = load_split_eeg_epochs(Path(\"/Users/depalati/mnt/rhino\"), epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_eeg_epochs(path, epochs) -> np.ndarray:\n",
    "    \"\"\"Load epochs from HDF5 EEG data.\n",
    "    \n",
    "    :param path: path to HDF5 file\n",
    "    :returns: EEG data\n",
    "    \n",
    "    \"\"\"\n",
    "    with h5py.File(path, \"r\") as hfile:\n",
    "        dset = hfile[\"eeg\"]\n",
    "        duration = epochs[0][1] - epochs[0][0]\n",
    "        array = np.empty((len(epochs), dset.shape[1], duration), dtype=dset.dtype)\n",
    "        for i, epoch in enumerate(epochs):\n",
    "            array[i, :] = dset[0, :, epoch[0]:epoch[1]]\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420 ms ± 2.86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "hdf_data = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/no_chunks.h5\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = load_split_eeg_epochs(Path(\"/Users/depalati/mnt/rhino\"), epochs)\n",
    "hdf_data = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/no_chunks.h5\", epochs)\n",
    "\n",
    "from numpy.testing import assert_equal\n",
    "assert_equal(split_data, hdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459 ms ± 11.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = load_hdf5_eeg_epochs(\"/Users/depalati/rhino_home/scratch/eeg_timeseries_no_compression.h5\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf_eeg_epochs_from_memory(path, epochs) -> np.ndarray:\n",
    "    with h5py.File(path, \"r\") as hfile:\n",
    "        data = hfile[\"eeg\"].value\n",
    "    \n",
    "    duration = epochs[0][1] - epochs[0][0]\n",
    "    array = np.empty((len(epochs), data.shape[1], duration), dtype=data.dtype)\n",
    "    \n",
    "    for i, epoch in enumerate(epochs):\n",
    "        array[i, :] = data[0, :, epoch[0]:epoch[1]]\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 ms ± 2.58 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = load_hdf_eeg_epochs_from_memory(\"/Users/depalati/rhino_home/scratch/no_chunks.h5\", epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading an entire session of data from a contiguous HDF5 file is *significantly* faster than using split EEG files.\n",
    "2. Loading epochs with HDF5 appears to be slightly worse than using memmaped split EEG files, but is of the same order of magnitude.\n",
    "3. Using chunking in HDF5 gives significantly worse performance for reading an entire session and doesn't seem to help things when reading epochs.\n",
    "4. Loading all data into memory before splitting into epochs is about twice as fast (for this dataset) as reading epochs directly from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is there a performance difference if we use PyTables for reading instead of HDF5?\n",
    "2. Can we get further benefits by changing how the data are laid out? For example, what if we use one array per channel instead of a single, large array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
